{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOt/JCvS5pBvcD732uBt4Pk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DeependraChaddha/Vlasov_Poisson_Solver/blob/main/vlasov_poisson_system_solver.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Script for Vlasov Poisson System Solver"
      ],
      "metadata": {
        "id": "YjWXXMEhh6wO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JlS9x6Q9hC8Q"
      },
      "outputs": [],
      "source": [
        "%%writefile vlasov_poisson_system.py\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.animation import FuncAnimation, PillowWriter\n",
        "from typing import Callable\n",
        "import tqdm\n",
        "\n",
        "class VlasovPoissonSolver:\n",
        "    def __init__(self, nx: int, nv: int, nt: int, x_range: tuple, v_range: tuple, t_range: tuple, device: str):\n",
        "        self.nx = nx\n",
        "        self.nv = nv\n",
        "        self.nt = nt\n",
        "        self.x_range = x_range\n",
        "        self.v_range = v_range\n",
        "        self.t_range = t_range\n",
        "        self.device = device if torch.cuda.is_available() else \"cpu\"\n",
        "        self.model_checkpoint_path = None\n",
        "        print(\"Instance of VlasovPoissonSolver created.\")\n",
        "\n",
        "    def make_grid(self):\n",
        "        x = torch.linspace(self.x_range[0], self.x_range[1], self.nx).reshape(-1, 1)\n",
        "        v = torch.linspace(self.v_range[0], self.v_range[1], self.nv).reshape(-1, 1)\n",
        "        t = torch.linspace(self.t_range[0], self.t_range[1], self.nt).reshape(-1, 1)\n",
        "\n",
        "        X, V, T = torch.meshgrid(x.squeeze(), v.squeeze(), t.squeeze(), indexing=\"ij\")\n",
        "\n",
        "        X = X.requires_grad_(True)\n",
        "        V = V.requires_grad_(True)\n",
        "        T = T.requires_grad_(True)\n",
        "\n",
        "        self.X = X.to(self.device)\n",
        "        self.V = V.to(self.device)\n",
        "        self.T = T.to(self.device)\n",
        "        return self.X, self.V, self.T\n",
        "\n",
        "    def save_checkpoint(self, model, optimizer, loss, model_name, hyperparameters):\n",
        "        checkpoint_dir = f\"checkpoint_{model_name}_nx{self.nx}_nv{self.nv}_nt{self.nt}_epochs{hyperparameters['epochs']}\"\n",
        "        os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "        checkpoint_path = os.path.join(checkpoint_dir, \"model_checkpoint.pkl\")\n",
        "        checkpoint = {\n",
        "            \"model_state_dict\": model.state_dict(),\n",
        "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "            \"loss\": loss,\n",
        "            \"hyperparameters\": hyperparameters,\n",
        "        }\n",
        "        torch.save(checkpoint, checkpoint_path)\n",
        "        self.model_checkpoint_path = checkpoint_path\n",
        "\n",
        "    def train_step(self, model, loss_fn, optimizer, scheduler=None):\n",
        "        # Forward Pass\n",
        "        prediction = model(self.X, self.V, self.T, self.nx, self.nv, self.nt)\n",
        "\n",
        "        # Compute Loss\n",
        "        loss = loss_fn(model, self.X, self.V, self.T, self.nx, self.nv, self.nt)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if scheduler:\n",
        "            scheduler.step(loss.item())\n",
        "\n",
        "        return loss.item(), model.state_dict()\n",
        "\n",
        "    def train(self, model, loss_fn, optimizer, epochs, model_name, get_loss_curve=False, scheduler=None):\n",
        "        try:\n",
        "            model = model.to(self.device)\n",
        "            best_loss = float(\"inf\")\n",
        "            loss_values = []\n",
        "\n",
        "            for epoch in tqdm.tqdm(range(epochs)):\n",
        "                loss, model_params = self.train_step(model, loss_fn, optimizer, scheduler)\n",
        "                loss_values.append(loss)\n",
        "\n",
        "                if loss < best_loss:\n",
        "                    best_loss = loss\n",
        "                    self.save_checkpoint(model, optimizer, loss, model_name, {\"epochs\": epochs})\n",
        "\n",
        "            print(f\"Best Loss Achieved: {best_loss}\")\n",
        "\n",
        "            if get_loss_curve:\n",
        "                plt.figure(figsize=(8, 5))\n",
        "                plt.plot(range(1, epochs + 1), loss_values, marker=\"o\", linestyle=\"-\", color=\"r\", label=\"Loss\")\n",
        "                plt.xlabel(\"Epoch\")\n",
        "                plt.ylabel(\"Loss\")\n",
        "                plt.title(\"Loss Curve Over Epochs\")\n",
        "                plt.legend()\n",
        "                plt.grid()\n",
        "                loss_curve_path = os.path.join(self.checkpoint_dir, \"loss_curve.png\")\n",
        "                plt.savefig(loss_curve_path)\n",
        "                print(f\"Loss curve saved at {loss_curve_path}\")\n",
        "                plt.show()\n",
        "\n",
        "            return self.model_checkpoint_path\n",
        "        except AttributeError:\n",
        "            print(\"Make grid first by calling make_grid()\")\n",
        "\n",
        "    def animate_final_prediction(self, model_class, model_checkpoint_path=None):\n",
        "        try:\n",
        "            if model_checkpoint_path is None:\n",
        "                if self.model_checkpoint_path is None:\n",
        "                    raise AttributeError(\"Model checkpoint not found. Train the model first.\")\n",
        "                model_checkpoint_path = self.model_checkpoint_path\n",
        "\n",
        "            checkpoint = torch.load(model_checkpoint_path, map_location=self.device)\n",
        "            model = model_class().to(self.device)\n",
        "            model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "            model.eval()\n",
        "\n",
        "            fig, ax = plt.subplots(figsize=(8, 6))\n",
        "\n",
        "            with torch.no_grad():\n",
        "                F_all = model(self.X, self.V, self.T, self.nx, self.nv, self.nt)  # Compute for all time steps\n",
        "\n",
        "            def update(frame):\n",
        "                ax.clear()\n",
        "                ax.imshow(F_all[:, :, frame].cpu().numpy(), extent=[self.x_range[0], self.x_range[1], self.v_range[0], self.v_range[1]], origin=\"lower\", cmap=\"viridis\")\n",
        "                ax.set_xlabel(\"x\")\n",
        "                ax.set_ylabel(\"v\")\n",
        "                ax.set_title(f\"Distribution Function at Time {frame}\")\n",
        "\n",
        "            ani = FuncAnimation(fig, update, frames=self.nt, repeat=False)\n",
        "\n",
        "            os.makedirs(self.checkpoint_dir, exist_ok=True)\n",
        "            animation_path = os.path.join(self.checkpoint_dir, \"vlasov_distribution.gif\")\n",
        "            ani.save(animation_path, writer=PillowWriter(fps=10))\n",
        "\n",
        "            self.model_checkpoint_path = animation_path\n",
        "            print(f\"Animation saved at: {animation_path}\")\n",
        "\n",
        "            plt.close(fig)\n",
        "            plt.show()\n",
        "        except AttributeError as e:\n",
        "            print(e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Using above script"
      ],
      "metadata": {
        "id": "HVS3hdeIiEJo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time_dependent_heat_equation  # Rename this module to match your modified version\n",
        "from time_dependent_heat_equation import TimeDependentHeatEquationSolver\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class DeepRitzVlasovPoisson(nn.Module):\n",
        "    def __init__(self, input_dim=3, hidden_dim=128, num_layers=8, use_fourier=True):\n",
        "        super().__init__()\n",
        "        self.use_fourier = use_fourier\n",
        "\n",
        "        self.input_layer = nn.Linear(hidden_dim if use_fourier else input_dim, hidden_dim)\n",
        "        self.hidden_layers = nn.ModuleList([nn.Linear(hidden_dim, hidden_dim) for _ in range(num_layers - 1)])\n",
        "        self.output_layer = nn.Linear(hidden_dim, 1)\n",
        "        self.activation = nn.SiLU()\n",
        "\n",
        "        if use_fourier:\n",
        "            self.freq_embedding = nn.Linear(input_dim, hidden_dim)\n",
        "            torch.nn.init.normal_(self.freq_embedding.weight, mean=0, std=1)\n",
        "\n",
        "    def forward(self, X, V, T, nx, nv, nt):\n",
        "        X, V, T = X.reshape(-1, 1), V.reshape(-1, 1), T.reshape(-1, 1)\n",
        "        inputs = torch.cat((X, V, T), dim=1)\n",
        "\n",
        "        if self.use_fourier:\n",
        "            inputs = torch.sin(self.freq_embedding(inputs))\n",
        "\n",
        "        x = self.activation(self.input_layer(inputs))  # Now input matches dimensions\n",
        "\n",
        "        for layer in self.hidden_layers:\n",
        "            residual = x\n",
        "            x = self.activation(layer(x)) + residual\n",
        "\n",
        "        return self.output_layer(x).view(nx, nv, nt)  # Ensure correct shape\n",
        "\n",
        "model = DeepRitzVlasovPoisson()\n",
        "\n",
        "'''Defining Loss function'''\n",
        "def loss_fn(model: nn.Module, x: torch.Tensor, v: torch.Tensor, t: torch.Tensor,\n",
        "            nx: int, nv: int, nt: int,\n",
        "            boundary_loss_weight: float = 2.0,\n",
        "            initial_loss_weight: float = 2.0):\n",
        "\n",
        "    prediction = model(x, v, t, nx, nv, nt)\n",
        "\n",
        "    # Compute first-order gradients\n",
        "    f_x = torch.autograd.grad(prediction, x, torch.ones_like(prediction), create_graph=True)[0]\n",
        "    f_v = torch.autograd.grad(prediction, v, torch.ones_like(prediction), create_graph=True)[0]\n",
        "    f_t = torch.autograd.grad(prediction, t, torch.ones_like(prediction), create_graph=True)[0]\n",
        "\n",
        "    # Compute the electric field by integrating f(x, v, t) over v\n",
        "    rho = torch.trapz(prediction, v, dim=1)  # Charge density (integrating over v)\n",
        "    E_x = torch.autograd.grad(rho, x, torch.ones_like(rho), create_graph=True)[0]  # ∂E/∂x = 1 - ρ\n",
        "\n",
        "    # Vlasov equation loss: ∂f/∂t + v∂f/∂x + E∂f/∂v = 0\n",
        "    pde_loss = torch.mean((f_t + v * f_x + E_x * f_v) ** 2)\n",
        "\n",
        "    # Boundary conditions (periodic in x, decay in v)\n",
        "    boundary_loss = (\n",
        "        (prediction[0, :, :] - prediction[-1, :, :])**2 +  # Periodic in x\n",
        "        (prediction[:, 0, :] - torch.zeros_like(prediction[:, 0, :]))**2 +  # Decay in v\n",
        "        (prediction[:, -1, :] - torch.zeros_like(prediction[:, -1, :]))**2\n",
        "    ).mean()\n",
        "\n",
        "    # Initial condition loss (e.g., Maxwellian or given distribution)\n",
        "    initial_condition = torch.exp(-v[:, :, 0]**2) * (1 + 0.1 * torch.cos(2 * torch.pi * x[:, :, 0]))\n",
        "    initial_condition_loss = torch.mean((prediction[:, :, 0] - initial_condition) ** 2)\n",
        "\n",
        "    total_loss = pde_loss + (boundary_loss_weight * boundary_loss) + (initial_loss_weight * initial_condition_loss)\n",
        "    return total_loss\n",
        "\n",
        "'''Set Optimizer'''\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "'''Add Scheduler'''\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)\n",
        "\n",
        "'''Make solver instance'''\n",
        "current_solver = TimeDependentHeatEquationSolver(nx=30, ny=30, nt=30, x_range=(0, 1), y_range=(-5, 5), t_range=(0, 1), device='cpu')\n",
        "\n",
        "'''Make Grid'''\n",
        "X, V, T = current_solver.make_grid()\n",
        "\n",
        "'''Train'''\n",
        "Z = current_solver.train(model=model,\n",
        "                         loss_fn=loss_fn,\n",
        "                         optimizer=optimizer,\n",
        "                         epochs=5,\n",
        "                         model_name='DeepRitz_VlasovPoisson',\n",
        "                         get_loss_curve=True,\n",
        "                         scheduler=scheduler)\n"
      ],
      "metadata": {
        "id": "PAbHn1LHiIQE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}